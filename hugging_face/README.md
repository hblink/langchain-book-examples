# Using local models

pip install -U torch langchain transformers llama_index

For CPU only, this speeds things up:

pip install xformers
